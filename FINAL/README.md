## ğŸ§  FINAL YEAR PROJECT â€” Multilingual Mental Health Chatbot (Free-First)

A compassionate, multilingual chatbot prototype for supportive conversations. It responds with empathy, detects crisis keywords, offers brief actionable steps, supports voice input/output, and displays avatar-style emojis to aid low-literacy users.

> Not a medical device. For emergencies, contact your local emergency number immediately.

---

### âœ¨ Highlights
- **Multilingual**: Understands and replies in the userâ€™s language
- **Empathetic responses**: FLAN-T5 with an empathy-tuned prompt
- **Actionable support plan**: 3â€“5 gentle, feasible next steps
- **Crisis awareness**: Keyword trigger â†’ show helpline guidance
- **Voice I/O**: Whisper STT, `pyttsx3` TTS (offline, Windows-friendly)
- **Accessible UI**: Emoji/Bitmoji-like avatars via OpenMoji
- **Free-first stack**: Colab, Streamlit, Hugging Face models

---

### ğŸ—ï¸ Architecture (Free-first)
- **Input**: Text (Streamlit), voice upload (Whisper)
- **NLP**:
  - Sentiment: `cardiffnlp/twitter-xlm-roberta-base-sentiment`
  - Empathy/NLG: `google/flan-t5-base`
  - Optional NLI: `joeddav/xlm-roberta-large-xnli`
- **Decision**: Basic crisis keywords â†’ helpline
- **Output**: Text + emoji avatar; optional TTS with `pyttsx3`
- **Deploy**: Local, Colab, or Hugging Face Spaces (Streamlit)

---

### ğŸ“¦ Repo Structure
- `app/nlp.py` â€” sentiment, empathetic reply, support plan
- `app/crisis.py` â€” crisis keyword detection + helpline
- `app/avatars.py` â€” emoji avatar mapping
- `app/voice.py` â€” Whisper STT + `pyttsx3` TTS
- `streamlit_app.py` â€” Streamlit chatbot UI
- `notebooks/colab_prototype.ipynb` â€” quick Colab demo

---

### ğŸš€ Quickstart (Local)
1) Install dependencies
```bash
pip install -r requirements.txt
```
2) Run the app
```bash
streamlit run streamlit_app.py
```
3) Optional: Enable STT/TTS in the sidebar
- STT uses Whisper (CPU ok, first run downloads weights)
- TTS uses `pyttsx3` (offline; Windows uses SAPI5 voices)

Requirements: Python 3.10â€“3.13, ffmpeg available in PATH (for audio handling)

---

### ğŸ§ª Colab Prototype
Open `notebooks/colab_prototype.ipynb` in Colab and run cells. Or install minimal deps directly in Colab:
```python
!pip install transformers datasets openai-whisper pyttsx3 emoji ffmpeg-python soundfile pydub
```

---

### ğŸ§© How It Works
- The bot detects a coarse sentiment label and crafts a warm, validating response in the same language.
- It proposes a short support plan (3â€“5 bullet points) with simple, immediate steps (grounding, self-care, optional social/pro support).
- If high-risk keywords are present, it surfaces a neutral, non-diagnostic helpline prompt.

---

### ğŸ”’ Privacy & Safety
- No PII storage by default. Add an explicit optâ€‘in before logging any data.
- No medical claims or diagnoses. Crisis prompts suggest contacting local services.
- For production, add locale-aware helplines and human-in-the-loop review.

---

### ğŸ› ï¸ Tuning & Extensibility
- Adjust tone/length in `NLPModels.generate_empathetic_reply` and `generate_support_plan`.
- Replace models with distilled or quantized variants for offline/rural devices.
- Swap STT with `whisper.cpp` for ultraâ€‘light CPU inference.
- Add multi-country helpline localization in `app/crisis.py`.

---

### ğŸ—ºï¸ Roadmap
- Emotion taxonomy beyond sentiment (multi-label)
- Session memory + safety rails (content filters)
- UI polish (theming, larger emoji avatars, voice recorder)
- Model caching and ONNX/ggml exports for offline

---

### ğŸ™ Acknowledgements
- Hugging Face models and datasets
- OpenMoji project (`https://openmoji.org`)
- Whisper (OpenAI) and pyttsx3 community

---

### ğŸ“„ License
Research prototype. Ensure compliance with local laws and platform policies when deploying.
